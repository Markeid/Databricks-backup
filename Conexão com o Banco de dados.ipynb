{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook contendo código de conexão com o Banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listagem dos scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferência das chaves do scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.secrets.list('--- Nome do Scope ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credenciais de conexão pelo modo SQL Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = '--- Nome do Database ---'\n",
    "server = '--- Nome do Server ---'\n",
    "port = '1433'\n",
    "user = '--- Nome do User ---'\n",
    "password = dbutils.secrets.get(scope = '--- Nome do Scope ---', key = 'db-password')\n",
    "stage = '--- Nome do Stage ---'\n",
    "jdbcURL = f\"jdbc:sqlserver://{server}:{port};database={database};user={user};password={password}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de escrita dos dados no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .format('jdbc') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option(\"url\", jdbcURL) \\\n",
    "    .option(\"databaseName\", database) \\\n",
    "    .option(\"dbtable\", stage) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de leitura dos dados no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark.read \\\n",
    "                .format('jdbc') \\\n",
    "                .option(\"url\", jdbcURL) \\\n",
    "                .option(\"databaseName\", database) \\\n",
    "                .option(\"dbtable\", stage) \\\n",
    "                .load()\n",
    "\n",
    "df_read.display()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
