{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando o upgrade do pip\n",
    "# Instalando a biblioteca pymssql\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Pandas, pymssql e adal\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando os dados da API e salvando em CSV\n",
    "\n",
    "api = \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial=%2701-01-2019%27&@dataFinalCotacao=%2712-31-2025%27&$top=9000&$format=text/csv&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\"\n",
    "csv = pd.read_csv(api)\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Spark e Functions\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando DataFrame\n",
    "\n",
    "df = spark.createDataFrame(csv)\n",
    "display(df)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acessando o Azure SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install msal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Id do locatário/locatário: Localizado em Registros de Aplicativos do Azure Active Directory -> app-user-databricks\n",
    "tenant_id = 'b4920c82-7581-491a-9dab-cd2ade2f3ebd'\n",
    "\n",
    "#Autoridade:\n",
    "msal_authority = 'https://login.windows.net/' + tenant_id\n",
    "   \n",
    "#url do recurso database\n",
    "resource_url = 'https://database.windows.net/.default'\n",
    "   \n",
    "# Service Principal Client ID - Criado em secrets no Key Vault\n",
    "service_principal_id = dbutils.secrets.get(scope = 'scope-adb-estudos', key = 'app-reg-adb')\n",
    "       \n",
    "# Service Principal Secret - Criado em secrets no Key Vault\n",
    "service_principal_secret = dbutils.secrets.get(scope = 'scope-adb-estudos', key = 'app-user-databricks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis e string de conexão ao Azure SQL Server\n",
    "jdbcHostname  = 'sql-estudo.database.windows.net'\n",
    "jdbcDatabase  = 'db-estudos'\n",
    "jdbcPort      = 1433\n",
    "jdbcUrl       = f'jdbc:sqlserver://{jdbcHostname}:{jdbcPort};database={jdbcDatabase}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a instância que sera usada durante todo o ciclo de vida do aplicativo.\n",
    "instance = msal.ConfidentialClientApplication(service_principal_id, service_principal_secret, msal_authority)\n",
    "   \n",
    "#Enviando solicitação ao AAD para obter um token.\n",
    "token = instance.acquire_token_for_client(resource_url)\n",
    "   \n",
    "#acesando o token\n",
    "access_token = token['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inseridos os dados na tabela Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo os dados na tabela stage\n",
    "\n",
    "table = 'dolar_marcus_araujo.dolar_stage_marcus_araujo02'\n",
    "\n",
    "df.write\\\n",
    "    .format('jdbc')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('url', jdbcUrl)\\\n",
    "    .option('databaseName', jdbcDatabase)\\\n",
    "    .option('dbtable', table)\\\n",
    "    .option('accesstoken', access_token)\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos dados na tabela stage\n",
    "\n",
    "df_read = spark.read\\\n",
    "            .format('jdbc')\\\n",
    "            .option('url', jdbcUrl)\\\n",
    "            .option('databaseName', jdbcDatabase)\\\n",
    "            .option('dbtable', table)\\\n",
    "            .option('accesstoken', access_token)\\\n",
    "            .load()\n",
    "\n",
    "display(df_read)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
